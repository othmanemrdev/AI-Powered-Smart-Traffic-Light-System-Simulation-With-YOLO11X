{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324ced17-bcf1-4f14-a42e-eab1f92c1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (1).jpg: 640x640 3 persons, 5 cars, 5 trucks, 739.2ms\n",
      "Speed: 11.0ms preprocess, 739.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class index detected: 7\n",
      "Class index detected: 0\n",
      "Class index detected: 2\n",
      "Class index detected: 0\n",
      "Class index detected: 7\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 0\n",
      "Class index detected: 2\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (1).jpg: 640x640 3 persons, 5 cars, 5 trucks, 606.6ms\n",
      "Speed: 6.0ms preprocess, 606.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (9).jpg: 640x640 2 cars, 2 trucks, 587.6ms\n",
      "Speed: 6.8ms preprocess, 587.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 10\n",
      "Total vehicles on road 2: 4\n",
      "Processed image (1).jpg and image (9).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (2).jpg: 640x640 1 person, 4 cars, 1 bus, 2 trucks, 1 traffic light, 708.2ms\n",
      "Speed: 6.0ms preprocess, 708.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (10).jpg: 640x640 3 persons, 6 cars, 4 trucks, 631.0ms\n",
      "Speed: 7.1ms preprocess, 631.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 7\n",
      "Total vehicles on road 2: 10\n",
      "Processed image (2).jpg and image (10).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (3).jpg: 640x640 4 cars, 3 buss, 2 trucks, 658.7ms\n",
      "Speed: 2.5ms preprocess, 658.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (11).jpg: 640x640 2 persons, 3 cars, 1 motorcycle, 4 trucks, 1 traffic light, 646.9ms\n",
      "Speed: 3.0ms preprocess, 646.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 9\n",
      "Total vehicles on road 2: 8\n",
      "Processed image (3).jpg and image (11).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (4).jpg: 640x640 6 cars, 749.2ms\n",
      "Speed: 5.0ms preprocess, 749.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (12).jpg: 640x640 2 persons, 4 cars, 3 trucks, 680.6ms\n",
      "Speed: 4.0ms preprocess, 680.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 6\n",
      "Total vehicles on road 2: 7\n",
      "Processed image (4).jpg and image (12).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (5).jpg: 640x640 6 cars, 3 buss, 3 trucks, 1 traffic light, 741.5ms\n",
      "Speed: 4.0ms preprocess, 741.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (13).jpg: 640x640 6 cars, 2 buss, 4 trucks, 781.9ms\n",
      "Speed: 5.0ms preprocess, 781.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 12\n",
      "Total vehicles on road 2: 12\n",
      "Processed image (5).jpg and image (13).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (6).jpg: 640x640 2 persons, 5 cars, 2 trucks, 634.9ms\n",
      "Speed: 5.0ms preprocess, 634.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (14).jpg: 640x640 1 person, 8 cars, 693.9ms\n",
      "Speed: 3.5ms preprocess, 693.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 7\n",
      "Total vehicles on road 2: 8\n",
      "Processed image (6).jpg and image (14).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (7).jpg: 640x640 1 person, 7 cars, 1 motorcycle, 1 bus, 4 trucks, 751.1ms\n",
      "Speed: 8.0ms preprocess, 751.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (15).jpg: 640x640 1 person, 7 cars, 2 buss, 3 trucks, 833.4ms\n",
      "Speed: 4.4ms preprocess, 833.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 13\n",
      "Total vehicles on road 2: 12\n",
      "Processed image (7).jpg and image (15).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (8).jpg: 640x640 6 cars, 4 trucks, 704.5ms\n",
      "Speed: 5.4ms preprocess, 704.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (16).jpg: 640x640 2 persons, 1 bicycle, 6 cars, 1 bus, 2 trucks, 1 traffic light, 627.7ms\n",
      "Speed: 3.0ms preprocess, 627.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 10\n",
      "Total vehicles on road 2: 9\n",
      "Processed image (8).jpg and image (16).jpg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tkinter as tk\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Traffic Light Simulation\")\n",
    "\n",
    "# Create canvas for two lights\n",
    "canvas = tk.Canvas(window, width=800, height=400)\n",
    "canvas.pack()\n",
    "\n",
    "# Draw two traffic lights with initial red light\n",
    "light1_red = canvas.create_oval(50, 20, 150, 120, fill=\"red\")\n",
    "light1_orange = canvas.create_oval(50, 125, 150, 175, fill=\"gray\")\n",
    "light1_green = canvas.create_oval(50, 180, 150, 280, fill=\"gray\")\n",
    "\n",
    "light2_red = canvas.create_oval(250, 20, 350, 120, fill=\"red\")\n",
    "light2_orange = canvas.create_oval(250, 125, 350, 175, fill=\"gray\")\n",
    "light2_green = canvas.create_oval(250, 180, 350, 280, fill=\"gray\")\n",
    "\n",
    "# Create labels to display vehicle counts and timers\n",
    "label_info = tk.Label(window, text=\"\", font=(\"Arial\", 14))\n",
    "label_info.pack()\n",
    "\n",
    "# Create a frame to hold the images\n",
    "frame_images = tk.Frame(window)\n",
    "frame_images.pack()\n",
    "\n",
    "# Helper function to set light colors\n",
    "def set_light(light_red, light_orange, light_green, color):\n",
    "    colors = {\"red\": (\"red\", \"gray\", \"gray\"), \n",
    "              \"orange\": (\"gray\", \"orange\", \"gray\"), \n",
    "              \"green\": (\"gray\", \"gray\", \"green\")}\n",
    "    canvas.itemconfig(light_red, fill=colors[color][0])\n",
    "    canvas.itemconfig(light_orange, fill=colors[color][1])\n",
    "    canvas.itemconfig(light_green, fill=colors[color][2])\n",
    "    window.update()\n",
    "\n",
    "# Function to control traffic lights based on vehicle count\n",
    "def update_lights(vehicles_road1, vehicles_road2, default_green_time=25, orange_time=5):\n",
    "    # Update label info with vehicle counts\n",
    "    label_info.config(text=f\"Vehicles Road 1: {vehicles_road1}, Vehicles Road 2: {vehicles_road2}\")\n",
    "    \n",
    "    if abs(vehicles_road1 - vehicles_road2) <= 3:\n",
    "        # Balanced traffic, default green light time\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        \n",
    "    elif vehicles_road1 > vehicles_road2:\n",
    "        # More traffic on road 1, extend green time\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time + min(60, (vehicles_road1 - vehicles_road2) * 2))\n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "    else:\n",
    "        # More traffic on road 2, extend green time\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time + min(60, (vehicles_road2 - vehicles_road1) * 2))\n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "\n",
    "# Define the paths to the images for both roads\n",
    "images_road1 = [f\"image ({i}).jpg\" for i in range(1, 9)]\n",
    "images_road2 = [f\"image ({i}).jpg\" for i in range(9, 17)]\n",
    "\n",
    "# Step 1: Print all class indices detected by YOLO for an image\n",
    "sample_results = model(images_road1[0])  # Run on a sample image\n",
    "for box in sample_results[0].boxes.data:\n",
    "    print(f\"Class index detected: {int(box[-1])}\")\n",
    "\n",
    "# Update vehicle_classes based on the printed indices for your model\n",
    "vehicle_classes = [2, 3, 5, 7]  # Example class indices (e.g., 2: car, 3: truck, etc.)\n",
    "\n",
    "# Step 2: Count all detected vehicle types based on the identified indices\n",
    "for image_path_road1, image_path_road2 in zip(images_road1, images_road2):\n",
    "    # Run YOLO prediction for both images\n",
    "    results_road1 = model(image_path_road1)\n",
    "    results_road2 = model(image_path_road2)\n",
    "\n",
    "    # Count all detected vehicle classes in each road's image\n",
    "    vehicles_road1 = sum(1 for box in results_road1[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "    vehicles_road2 = sum(1 for box in results_road2[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "\n",
    "    print(f\"Total vehicles on road 1: {vehicles_road1}\")\n",
    "    print(f\"Total vehicles on road 2: {vehicles_road2}\")\n",
    "\n",
    "    # Update traffic lights based on YOLO results\n",
    "    update_lights(vehicles_road1, vehicles_road2)\n",
    "\n",
    "    # Display images after prediction\n",
    "    img1 = ImageTk.PhotoImage(Image.open(image_path_road1).resize((200, 150)))\n",
    "    img2 = ImageTk.PhotoImage(Image.open(image_path_road2).resize((200, 150)))\n",
    "    \n",
    "    # Clear previous images\n",
    "    for widget in frame_images.winfo_children():\n",
    "        widget.destroy()\n",
    "        \n",
    "    # Display the current images\n",
    "    label_road1 = tk.Label(frame_images, image=img1)\n",
    "    label_road1.image = img1  # Keep a reference to avoid garbage collection\n",
    "    label_road1.pack(side=tk.LEFT)\n",
    "\n",
    "    label_road2 = tk.Label(frame_images, image=img2)\n",
    "    label_road2.image = img2  # Keep a reference to avoid garbage collection\n",
    "    label_road2.pack(side=tk.LEFT)\n",
    "\n",
    "    # Log or save results as needed for each image\n",
    "    print(f\"Processed {image_path_road1} and {image_path_road2}\")\n",
    "\n",
    "    # Add a delay to simulate a real camera feed\n",
    "    time.sleep(1)  # Delay of 1 second\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d107d-9447-4ca4-a5a2-bb62991b55e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (1).jpg: 640x640 3 persons, 5 cars, 5 trucks, 801.4ms\n",
      "Speed: 4.0ms preprocess, 801.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class index detected: 7\n",
      "Class index detected: 0\n",
      "Class index detected: 2\n",
      "Class index detected: 0\n",
      "Class index detected: 7\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 0\n",
      "Class index detected: 2\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (1).jpg: 640x640 3 persons, 5 cars, 5 trucks, 637.0ms\n",
      "Speed: 3.6ms preprocess, 637.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (9).jpg: 640x640 2 cars, 2 trucks, 655.9ms\n",
      "Speed: 5.2ms preprocess, 655.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 10\n",
      "Total vehicles on road 2: 4\n",
      "Road 1 has more traffic. Green time = 37\n",
      "Orange time = 5\n",
      "Road 2 green time = 25\n",
      "Orange time = 5\n",
      "Processed image (1).jpg and image (9).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (2).jpg: 640x640 1 person, 4 cars, 1 bus, 2 trucks, 1 traffic light, 679.8ms\n",
      "Speed: 7.0ms preprocess, 679.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (10).jpg: 640x640 3 persons, 6 cars, 4 trucks, 699.5ms\n",
      "Speed: 7.1ms preprocess, 699.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 7\n",
      "Total vehicles on road 2: 10\n",
      "Balanced traffic condition: green time = 25\n",
      "Orange time = 5\n",
      "Orange time = 5\n",
      "Processed image (2).jpg and image (10).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (3).jpg: 640x640 4 cars, 3 buss, 2 trucks, 717.6ms\n",
      "Speed: 8.0ms preprocess, 717.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (11).jpg: 640x640 2 persons, 3 cars, 1 motorcycle, 4 trucks, 1 traffic light, 667.0ms\n",
      "Speed: 4.0ms preprocess, 667.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 9\n",
      "Total vehicles on road 2: 8\n",
      "Balanced traffic condition: green time = 25\n",
      "Orange time = 5\n",
      "Orange time = 5\n",
      "Processed image (3).jpg and image (11).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (4).jpg: 640x640 6 cars, 767.2ms\n",
      "Speed: 4.3ms preprocess, 767.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (12).jpg: 640x640 2 persons, 4 cars, 3 trucks, 751.8ms\n",
      "Speed: 6.2ms preprocess, 751.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 6\n",
      "Total vehicles on road 2: 7\n",
      "Balanced traffic condition: green time = 25\n",
      "Orange time = 5\n",
      "Orange time = 5\n",
      "Processed image (4).jpg and image (12).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (5).jpg: 640x640 6 cars, 3 buss, 3 trucks, 1 traffic light, 630.6ms\n",
      "Speed: 5.0ms preprocess, 630.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (13).jpg: 640x640 6 cars, 2 buss, 4 trucks, 741.1ms\n",
      "Speed: 5.0ms preprocess, 741.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 12\n",
      "Total vehicles on road 2: 12\n",
      "Balanced traffic condition: green time = 25\n",
      "Orange time = 5\n",
      "Orange time = 5\n",
      "Processed image (5).jpg and image (13).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (6).jpg: 640x640 2 persons, 5 cars, 2 trucks, 652.2ms\n",
      "Speed: 4.1ms preprocess, 652.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\image (14).jpg: 640x640 1 person, 8 cars, 618.8ms\n",
      "Speed: 4.0ms preprocess, 618.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Total vehicles on road 1: 7\n",
      "Total vehicles on road 2: 8\n",
      "Balanced traffic condition: green time = 25\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tkinter as tk\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Traffic Light Simulation\")\n",
    "\n",
    "# Create canvas for two lights\n",
    "canvas = tk.Canvas(window, width=800, height=400)\n",
    "canvas.pack()\n",
    "\n",
    "# Draw two traffic lights with initial red light\n",
    "light1_red = canvas.create_oval(50, 20, 150, 120, fill=\"red\")\n",
    "light1_orange = canvas.create_oval(50, 125, 150, 175, fill=\"gray\")\n",
    "light1_green = canvas.create_oval(50, 180, 150, 280, fill=\"gray\")\n",
    "\n",
    "light2_red = canvas.create_oval(250, 20, 350, 120, fill=\"red\")\n",
    "light2_orange = canvas.create_oval(250, 125, 350, 175, fill=\"gray\")\n",
    "light2_green = canvas.create_oval(250, 180, 350, 280, fill=\"gray\")\n",
    "\n",
    "# Create labels to display vehicle counts and timers\n",
    "label_info = tk.Label(window, text=\"\", font=(\"Arial\", 14))\n",
    "label_info.pack()\n",
    "\n",
    "# Create a frame to hold the images\n",
    "frame_images = tk.Frame(window)\n",
    "frame_images.pack()\n",
    "\n",
    "# Helper function to set light colors\n",
    "def set_light(light_red, light_orange, light_green, color, time=0):\n",
    "    colors = {\"red\": (\"red\", \"gray\", \"gray\"), \n",
    "              \"orange\": (\"gray\", \"orange\", \"gray\"), \n",
    "              \"green\": (\"gray\", \"gray\", \"green\")}\n",
    "    canvas.itemconfig(light_red, fill=colors[color][0])\n",
    "    canvas.itemconfig(light_orange, fill=colors[color][1])\n",
    "    canvas.itemconfig(light_green, fill=colors[color][2])\n",
    "    window.update()\n",
    "\n",
    "# Function to control traffic lights based on vehicle count\n",
    "def update_lights(vehicles_road1, vehicles_road2, default_green_time=25, orange_time=5):\n",
    "    # Update label info with vehicle counts\n",
    "    label_info.config(text=f\"Vehicles Road 1: {vehicles_road1}, Vehicles Road 2: {vehicles_road2}\")\n",
    "    \n",
    "    if abs(vehicles_road1 - vehicles_road2) <= 3:\n",
    "        # Balanced traffic, default green light time\n",
    "        print(f\"Balanced traffic condition: green time = {default_green_time}\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        print(f\"Orange time = {orange_time}\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        print(f\"Orange time = {orange_time}\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        \n",
    "    elif vehicles_road1 > vehicles_road2:\n",
    "        # More traffic on road 1, extend green time\n",
    "        additional_time = min(60, (vehicles_road1 - vehicles_road2) * 2)\n",
    "        print(f\"Road 1 has more traffic. Green time = {default_green_time + additional_time}\")\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time + additional_time)\n",
    "        \n",
    "        print(f\"Orange time = {orange_time}\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        print(f\"Road 2 green time = {default_green_time}\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        print(f\"Orange time = {orange_time}\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "    else:\n",
    "        # More traffic on road 2, extend green time\n",
    "        additional_time = min(60, (vehicles_road2 - vehicles_road1) * 2)\n",
    "        print(f\"Road 2 has more traffic. Green time = {default_green_time + additional_time}\")\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time + additional_time)\n",
    "        \n",
    "        print(f\"Orange time = {orange_time}\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        print(f\"Road 1 green time = {default_green_time}\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        print(f\"Orange time = {orange_time}\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "\n",
    "# Define the paths to the images for both roads\n",
    "images_road1 = [f\"image ({i}).jpg\" for i in range(1, 9)]\n",
    "images_road2 = [f\"image ({i}).jpg\" for i in range(9, 17)]\n",
    "\n",
    "# Step 1: Print all class indices detected by YOLO for an image\n",
    "sample_results = model(images_road1[0])  # Run on a sample image\n",
    "for box in sample_results[0].boxes.data:\n",
    "    print(f\"Class index detected: {int(box[-1])}\")\n",
    "\n",
    "# Update vehicle_classes based on the printed indices for your model\n",
    "vehicle_classes = [2, 3, 5, 7]  # Example class indices (e.g., 2: car, 3: truck, etc.)\n",
    "\n",
    "# Step 2: Count all detected vehicle types based on the identified indices\n",
    "for image_path_road1, image_path_road2 in zip(images_road1, images_road2):\n",
    "    # Run YOLO prediction for both images\n",
    "    results_road1 = model(image_path_road1)\n",
    "    results_road2 = model(image_path_road2)\n",
    "\n",
    "    # Count all detected vehicle classes in each road's image\n",
    "    vehicles_road1 = sum(1 for box in results_road1[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "    vehicles_road2 = sum(1 for box in results_road2[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "\n",
    "    print(f\"Total vehicles on road 1: {vehicles_road1}\")\n",
    "    print(f\"Total vehicles on road 2: {vehicles_road2}\")\n",
    "\n",
    "    # Update traffic lights based on YOLO results\n",
    "    update_lights(vehicles_road1, vehicles_road2)\n",
    "\n",
    "    # Display images after prediction\n",
    "    img1 = ImageTk.PhotoImage(Image.open(image_path_road1).resize((200, 150)))\n",
    "    img2 = ImageTk.PhotoImage(Image.open(image_path_road2).resize((200, 150)))\n",
    "    \n",
    "    # Clear previous images\n",
    "    for widget in frame_images.winfo_children():\n",
    "        widget.destroy()\n",
    "        \n",
    "    # Display the current images\n",
    "    label_road1 = tk.Label(frame_images, image=img1)\n",
    "    label_road1.image = img1  # Keep a reference to avoid garbage collection\n",
    "    label_road1.pack(side=tk.LEFT)\n",
    "\n",
    "    label_road2 = tk.Label(frame_images, image=img2)\n",
    "    label_road2.image = img2  # Keep a reference to avoid garbage collection\n",
    "    label_road2.pack(side=tk.LEFT)\n",
    "\n",
    "    # Log or save results as needed for each image\n",
    "    print(f\"Processed {image_path_road1} and {image_path_road2}\")\n",
    "\n",
    "    # Add a delay to simulate a real camera feed\n",
    "    time.sleep(1)  # Delay of 1 second\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30838ab7-8e45-4783-ba78-dda7c51e0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image1.jpeg: 480x640 12 cars, 4 trucks, 589.1ms\n",
      "Speed: 4.9ms preprocess, 589.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 7\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "Class index detected: 2\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image1.jpeg: 480x640 12 cars, 4 trucks, 578.4ms\n",
      "Speed: 6.5ms preprocess, 578.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image9.jpeg: 480x640 11 cars, 4 trucks, 494.5ms\n",
      "Speed: 3.0ms preprocess, 494.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Balanced traffic condition: green time = 25\n",
      "Road 1 green time: 25, Orange time: 5\n",
      "Road 2 green time: 25, Orange time: 5\n",
      "Total vehicles on road 1: 16\n",
      "Total vehicles on road 2: 15\n",
      "Processed pic2\\image1.jpeg and pic2\\image9.jpeg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image2.jpeg: 480x640 16 cars, 5 trucks, 502.3ms\n",
      "Speed: 4.0ms preprocess, 502.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image10.jpeg: 480x640 14 cars, 5 trucks, 501.4ms\n",
      "Speed: 3.5ms preprocess, 501.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Balanced traffic condition: green time = 25\n",
      "Road 1 green time: 25, Orange time: 5\n",
      "Road 2 green time: 25, Orange time: 5\n",
      "Total vehicles on road 1: 21\n",
      "Total vehicles on road 2: 19\n",
      "Processed pic2\\image2.jpeg and pic2\\image10.jpeg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image3.jpeg: 480x640 14 cars, 1 truck, 495.8ms\n",
      "Speed: 3.5ms preprocess, 495.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic2\\image11.jpeg: 480x640 17 cars, 2 trucks, 516.3ms\n",
      "Speed: 3.0ms preprocess, 516.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Road 2 has more traffic. Green time = 33\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tkinter as tk\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageTk, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Traffic Light Simulation\")\n",
    "\n",
    "# Create canvas for two lights\n",
    "canvas = tk.Canvas(window, width=800, height=400)\n",
    "canvas.pack()\n",
    "\n",
    "# Draw two traffic lights with initial red light\n",
    "light1_red = canvas.create_oval(50, 20, 150, 120, fill=\"red\")\n",
    "light1_orange = canvas.create_oval(50, 125, 150, 175, fill=\"gray\")\n",
    "light1_green = canvas.create_oval(50, 180, 150, 280, fill=\"gray\")\n",
    "\n",
    "light2_red = canvas.create_oval(250, 20, 350, 120, fill=\"red\")\n",
    "light2_orange = canvas.create_oval(250, 125, 350, 175, fill=\"gray\")\n",
    "light2_green = canvas.create_oval(250, 180, 350, 280, fill=\"gray\")\n",
    "\n",
    "# Create labels to display vehicle counts and timers\n",
    "label_info = tk.Label(window, text=\"\", font=(\"Arial\", 14))\n",
    "label_info.pack()\n",
    "\n",
    "# Create a frame to hold the images\n",
    "frame_images = tk.Frame(window)\n",
    "frame_images.pack()\n",
    "\n",
    "# Helper function to set light colors\n",
    "def set_light(light_red, light_orange, light_green, color, time=0):\n",
    "    colors = {\"red\": (\"red\", \"gray\", \"gray\"), \n",
    "              \"orange\": (\"gray\", \"orange\", \"gray\"), \n",
    "              \"green\": (\"gray\", \"gray\", \"green\")}\n",
    "    canvas.itemconfig(light_red, fill=colors[color][0])\n",
    "    canvas.itemconfig(light_orange, fill=colors[color][1])\n",
    "    canvas.itemconfig(light_green, fill=colors[color][2])\n",
    "    window.update()\n",
    "\n",
    "def draw_bounding_boxes(image_path, results):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for box in results[0].boxes.data:\n",
    "        x1, y1, x2, y2 = box[:4]  # Get the coordinates of the bounding box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Function to control traffic lights based on vehicle count\n",
    "def update_lights(vehicles_road1, vehicles_road2, default_green_time=25, orange_time=5):\n",
    "    # Update label info with vehicle counts\n",
    "    label_info.config(text=f\"Vehicles Road 1: {vehicles_road1}, Vehicles Road 2: {vehicles_road2}\")\n",
    "    \n",
    "    # Set up variables to hold the traffic light timings for printing\n",
    "    green_time_road1 = default_green_time\n",
    "    green_time_road2 = default_green_time\n",
    "    orange_time_road1 = orange_time\n",
    "    orange_time_road2 = orange_time\n",
    "    \n",
    "    if abs(vehicles_road1 - vehicles_road2) <= 3:\n",
    "        # Balanced traffic, default green light time\n",
    "        print(f\"Balanced traffic condition: green time = {default_green_time}\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        \n",
    "    elif vehicles_road1 > vehicles_road2:\n",
    "        # More traffic on road 1, extend green time\n",
    "        additional_time = min(60, (vehicles_road1 - vehicles_road2) * 2)\n",
    "        green_time_road1 += additional_time\n",
    "        print(f\"Road 1 has more traffic. Green time = {green_time_road1}\")\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(green_time_road1)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "    else:\n",
    "        # More traffic on road 2, extend green time\n",
    "        additional_time = min(60, (vehicles_road2 - vehicles_road1) * 2)\n",
    "        green_time_road2 += additional_time\n",
    "        print(f\"Road 2 has more traffic. Green time = {green_time_road2}\")\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(green_time_road2)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "    \n",
    "    return green_time_road1, green_time_road2, orange_time_road1, orange_time_road2\n",
    "\n",
    "\n",
    "# Define the paths to the images for both roads\n",
    "# images_road1 = [f\"pic1\\\\image ({i}).jpg\" for i in range(1, 9)]\n",
    "# images_road2 = [f\"pic1\\\\image ({i}).jpg\" for i in range(9, 17)]\n",
    "\n",
    "images_road1 = [f\"pic2\\\\image{i}.jpeg\" for i in range(1, 9)]\n",
    "images_road2 = [f\"pic2\\\\image{i}.jpeg\" for i in range(9, 17)]\n",
    "\n",
    "# Step 1: Print all class indices detected by YOLO for an image\n",
    "sample_results = model(images_road1[0])  # Run on a sample image\n",
    "for box in sample_results[0].boxes.data:\n",
    "    print(f\"Class index detected: {int(box[-1])}\")\n",
    "\n",
    "# Update vehicle_classes based on the printed indices for your model\n",
    "vehicle_classes = [2, 3, 5, 7]  # Example class indices (e.g., 2: car, 3: truck, etc.)\n",
    "\n",
    "# Step 2: Count all detected vehicle types based on the identified indices\n",
    "for image_path_road1, image_path_road2 in zip(images_road1, images_road2):\n",
    "    # Run YOLO prediction for both images\n",
    "    results_road1 = model(image_path_road1)\n",
    "    results_road2 = model(image_path_road2)\n",
    "  \n",
    "    # Count all detected vehicle classes in each road's image\n",
    "    vehicles_road1 = sum(1 for box in results_road1[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "    vehicles_road2 = sum(1 for box in results_road2[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update traffic lights based on YOLO results and capture returned values\n",
    "    green_time_road1, green_time_road2, orange_time_road1, orange_time_road2 = update_lights(vehicles_road1, vehicles_road2)\n",
    "\n",
    "    image_with_boxes1 = draw_bounding_boxes(image_path_road1, results_road1)\n",
    "    image_with_boxes2 = draw_bounding_boxes(image_path_road2, results_road2)\n",
    "    \n",
    "    # Print the green and orange times for both roads\n",
    "    print(f\"Road 1 green time: {green_time_road1}, Orange time: {orange_time_road1}\")\n",
    "    print(f\"Road 2 green time: {green_time_road2}, Orange time: {orange_time_road2}\")\n",
    "    print(f\"Total vehicles on road 1: {vehicles_road1}\")\n",
    "    print(f\"Total vehicles on road 2: {vehicles_road2}\")\n",
    "\n",
    "    # Display images after prediction\n",
    "    img1 = ImageTk.PhotoImage(image_with_boxes1.resize((400, 350)))\n",
    "    img2 = ImageTk.PhotoImage(image_with_boxes2.resize((400, 350)))\n",
    "    \n",
    "    # Clear previous images\n",
    "    for widget in frame_images.winfo_children():\n",
    "        widget.destroy()\n",
    "        \n",
    "    # Display the current images\n",
    "    label_road1 = tk.Label(frame_images, image=img1)\n",
    "    label_road1.image = img1  # Keep a reference to avoid garbage collection\n",
    "    label_road1.pack(side=tk.LEFT)\n",
    "\n",
    "    label_road2 = tk.Label(frame_images, image=img2)\n",
    "    label_road2.image = img2  # Keep a reference to avoid garbage collection\n",
    "    label_road2.pack(side=tk.LEFT)\n",
    "\n",
    "    # Log or save results as needed for each image\n",
    "    print(f\"Processed {image_path_road1} and {image_path_road2}\")\n",
    "\n",
    "    # Add a delay to simulate a real camera feed\n",
    "    time.sleep(1)  # Delay of 1 second\n",
    "\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a1c77-a028-4dbc-8034-58203b46ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pic2\\\\image1.jpeg', 'pic2\\\\image2.jpeg', 'pic2\\\\image3.jpeg', 'pic2\\\\image4.jpeg', 'pic2\\\\image5.jpeg', 'pic2\\\\image6.jpeg', 'pic2\\\\image7.jpeg', 'pic2\\\\image8.jpeg', 'pic2\\\\image9.jpeg', 'pic2\\\\image10.jpeg']\n",
      "\n",
      "0: 480x640 11 cars, 4 trucks, 518.4ms\n",
      "Speed: 6.0ms preprocess, 518.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the YOLO model\n",
    "model_path = \"best.pt\"  # Replace with your model's path\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# List of images to simulate incoming data\n",
    "image_names = [f\"pic2\\\\image{i}.jpeg\" for i in range(1, 11)]\n",
    "print(image_names)\n",
    "\n",
    "# Process each image with a delay\n",
    "for image_path in image_names:\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "    image = np.array(image)\n",
    "\n",
    "    # Run YOLO prediction\n",
    "    results = model(image)\n",
    "\n",
    "    # Plot the results\n",
    "    results[0].plot()  # Visualize predictions\n",
    "    plt.imshow(results[0].plot())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Log or save results as needed for each image\n",
    "    print(f\"Processed {image_path}\")\n",
    "\n",
    "    # Add a delay to simulate a real camera feed\n",
    "    time.sleep(1)  # Delay of 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923f4f5f-2e8f-401f-9e03-8fdd0ea77fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (1).jpg: 640x640 3 persons, 5 cars, 5 trucks, 939.8ms\n",
      "Speed: 7.0ms preprocess, 939.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Class index detected: 7\n",
      "Class index detected: 0\n",
      "Class index detected: 2\n",
      "Class index detected: 0\n",
      "Class index detected: 7\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 7\n",
      "Class index detected: 2\n",
      "Class index detected: 0\n",
      "Class index detected: 2\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (1).jpg: 640x640 3 persons, 5 cars, 5 trucks, 847.1ms\n",
      "Speed: 4.2ms preprocess, 847.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (9).jpg: 640x640 2 cars, 2 trucks, 807.1ms\n",
      "Speed: 5.5ms preprocess, 807.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Road 1 has more traffic. Green time = 17\n",
      "Road 1 green time: 17, Orange time: 1\n",
      "Road 2 green time: 5, Orange time: 1\n",
      "Total vehicles on road 1: 10\n",
      "Total vehicles on road 2: 4\n",
      "Processed pic1\\image (1).jpg and pic1\\image (9).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (2).jpg: 640x640 1 person, 4 cars, 1 bus, 2 trucks, 1 traffic light, 791.9ms\n",
      "Speed: 6.9ms preprocess, 791.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (10).jpg: 640x640 3 persons, 6 cars, 4 trucks, 889.3ms\n",
      "Speed: 24.7ms preprocess, 889.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Balanced traffic condition: green time = 5\n",
      "Road 1 green time: 5, Orange time: 1\n",
      "Road 2 green time: 5, Orange time: 1\n",
      "Total vehicles on road 1: 7\n",
      "Total vehicles on road 2: 10\n",
      "Processed pic1\\image (2).jpg and pic1\\image (10).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (3).jpg: 640x640 4 cars, 3 buss, 2 trucks, 671.4ms\n",
      "Speed: 3.1ms preprocess, 671.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (11).jpg: 640x640 2 persons, 3 cars, 1 motorcycle, 4 trucks, 1 traffic light, 705.6ms\n",
      "Speed: 3.6ms preprocess, 705.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Balanced traffic condition: green time = 5\n",
      "Road 1 green time: 5, Orange time: 1\n",
      "Road 2 green time: 5, Orange time: 1\n",
      "Total vehicles on road 1: 9\n",
      "Total vehicles on road 2: 8\n",
      "Processed pic1\\image (3).jpg and pic1\\image (11).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (4).jpg: 640x640 6 cars, 595.9ms\n",
      "Speed: 3.0ms preprocess, 595.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (12).jpg: 640x640 2 persons, 4 cars, 3 trucks, 620.5ms\n",
      "Speed: 4.0ms preprocess, 620.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Balanced traffic condition: green time = 5\n",
      "Road 1 green time: 5, Orange time: 1\n",
      "Road 2 green time: 5, Orange time: 1\n",
      "Total vehicles on road 1: 6\n",
      "Total vehicles on road 2: 7\n",
      "Processed pic1\\image (4).jpg and pic1\\image (12).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (5).jpg: 640x640 6 cars, 3 buss, 3 trucks, 1 traffic light, 681.5ms\n",
      "Speed: 3.0ms preprocess, 681.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (13).jpg: 640x640 6 cars, 2 buss, 4 trucks, 737.6ms\n",
      "Speed: 3.0ms preprocess, 737.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Balanced traffic condition: green time = 5\n",
      "Road 1 green time: 5, Orange time: 1\n",
      "Road 2 green time: 5, Orange time: 1\n",
      "Total vehicles on road 1: 12\n",
      "Total vehicles on road 2: 12\n",
      "Processed pic1\\image (5).jpg and pic1\\image (13).jpg\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (6).jpg: 640x640 2 persons, 5 cars, 2 trucks, 849.1ms\n",
      "Speed: 4.0ms preprocess, 849.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\othma\\Desktop\\ENSAJ\\S7 & S8\\S7\\IoT\\Projet\\Use case\\pic1\\image (14).jpg: 640x640 1 person, 8 cars, 793.8ms\n",
      "Speed: 4.6ms preprocess, 793.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Balanced traffic condition: green time = 5\n"
     ]
    },
    {
     "ename": "TclError",
     "evalue": "invalid command name \".!canvas\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 156\u001b[0m\n\u001b[0;32m    151\u001b[0m vehicles_road2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m results_road2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(box[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m vehicle_classes)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Update traffic lights based on YOLO results and capture returned values\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m green_time_road1, green_time_road2, orange_time_road1, orange_time_road2 \u001b[38;5;241m=\u001b[39m update_lights(vehicles_road1, vehicles_road2)\n\u001b[0;32m    158\u001b[0m image_with_boxes1 \u001b[38;5;241m=\u001b[39m draw_bounding_boxes(image_path_road1, results_road1)\n\u001b[0;32m    159\u001b[0m image_with_boxes2 \u001b[38;5;241m=\u001b[39m draw_bounding_boxes(image_path_road2, results_road2)\n",
      "Cell \u001b[1;32mIn[4], line 82\u001b[0m, in \u001b[0;36mupdate_lights\u001b[1;34m(vehicles_road1, vehicles_road2, default_green_time, orange_time)\u001b[0m\n\u001b[0;32m     79\u001b[0m     set_light(light2_red, light2_orange, light2_green, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     80\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(orange_time)\n\u001b[1;32m---> 82\u001b[0m     set_light(light2_red, light2_orange, light2_green, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m vehicles_road1 \u001b[38;5;241m>\u001b[39m vehicles_road2:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# More traffic on road 1, extend green time\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     additional_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m60\u001b[39m, (vehicles_road1 \u001b[38;5;241m-\u001b[39m vehicles_road2) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 40\u001b[0m, in \u001b[0;36mset_light\u001b[1;34m(light_red, light_orange, light_green, color, time)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_light\u001b[39m(light_red, light_orange, light_green, color, time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     37\u001b[0m     colors \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m     38\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[0;32m     39\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[1;32m---> 40\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mitemconfig(light_red, fill\u001b[38;5;241m=\u001b[39mcolors[color][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     41\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mitemconfig(light_orange, fill\u001b[38;5;241m=\u001b[39mcolors[color][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     42\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mitemconfig(light_green, fill\u001b[38;5;241m=\u001b[39mcolors[color][\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\tkinter\\__init__.py:2988\u001b[0m, in \u001b[0;36mCanvas.itemconfigure\u001b[1;34m(self, tagOrId, cnf, **kw)\u001b[0m\n\u001b[0;32m   2981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mitemconfigure\u001b[39m(\u001b[38;5;28mself\u001b[39m, tagOrId, cnf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m   2982\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Configure resources of an item TAGORID.\u001b[39;00m\n\u001b[0;32m   2983\u001b[0m \n\u001b[0;32m   2984\u001b[0m \u001b[38;5;124;03m    The values for resources are specified as keyword\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m \u001b[38;5;124;03m    arguments. To get an overview about\u001b[39;00m\n\u001b[0;32m   2986\u001b[0m \u001b[38;5;124;03m    the allowed keyword arguments call the method without arguments.\u001b[39;00m\n\u001b[0;32m   2987\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitemconfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, tagOrId), cnf, kw)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\tkinter\\__init__.py:1712\u001b[0m, in \u001b[0;36mMisc._configure\u001b[1;34m(self, cmd, cnf, kw)\u001b[0m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cnf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getconfigure1(_flatten((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w, cmd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcnf)))\n\u001b[1;32m-> 1712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mcall(_flatten((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w, cmd)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options(cnf))\n",
      "\u001b[1;31mTclError\u001b[0m: invalid command name \".!canvas\""
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tkinter as tk\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageTk, ImageDraw\n",
    "import cv2\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Traffic Light Simulation\")\n",
    "\n",
    "# Create canvas for two lights\n",
    "canvas = tk.Canvas(window, width=800, height=400)\n",
    "canvas.pack()\n",
    "\n",
    "# Draw two traffic lights with initial red light\n",
    "light1_red = canvas.create_oval(50, 20, 150, 120, fill=\"red\")\n",
    "light1_orange = canvas.create_oval(50, 125, 150, 175, fill=\"gray\")\n",
    "light1_green = canvas.create_oval(50, 180, 150, 280, fill=\"gray\")\n",
    "\n",
    "light2_red = canvas.create_oval(250, 20, 350, 120, fill=\"red\")\n",
    "light2_orange = canvas.create_oval(250, 125, 350, 175, fill=\"gray\")\n",
    "light2_green = canvas.create_oval(250, 180, 350, 280, fill=\"gray\")\n",
    "\n",
    "# Create labels to display vehicle counts and timers\n",
    "label_info = tk.Label(window, text=\"\", font=(\"Arial\", 14))\n",
    "label_info.pack()\n",
    "\n",
    "# Create a frame to hold the images\n",
    "frame_images = tk.Frame(window)\n",
    "frame_images.pack()\n",
    "\n",
    "# Helper function to set light colors\n",
    "def set_light(light_red, light_orange, light_green, color, time=0):\n",
    "    colors = {\"red\": (\"red\", \"gray\", \"gray\"), \n",
    "              \"orange\": (\"gray\", \"orange\", \"gray\"), \n",
    "              \"green\": (\"gray\", \"gray\", \"green\")}\n",
    "    canvas.itemconfig(light_red, fill=colors[color][0])\n",
    "    canvas.itemconfig(light_orange, fill=colors[color][1])\n",
    "    canvas.itemconfig(light_green, fill=colors[color][2])\n",
    "    window.update()\n",
    "\n",
    "def draw_bounding_boxes(image_path, results):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for box in results[0].boxes.data:\n",
    "        x1, y1, x2, y2 = box[:4]  # Get the coordinates of the bounding box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Function to control traffic lights based on vehicle count\n",
    "def update_lights(vehicles_road1, vehicles_road2, default_green_time=5, orange_time=1):\n",
    "    # Update label info with vehicle counts\n",
    "    label_info.config(text=f\"Vehicles Road 1: {vehicles_road1}, Vehicles Road 2: {vehicles_road2}\")\n",
    "    \n",
    "    # Set up variables to hold the traffic light timings for printing\n",
    "    green_time_road1 = default_green_time\n",
    "    green_time_road2 = default_green_time\n",
    "    orange_time_road1 = orange_time\n",
    "    orange_time_road2 = orange_time\n",
    "    \n",
    "    if abs(vehicles_road1 - vehicles_road2) <= 3:\n",
    "        # Balanced traffic, default green light time\n",
    "        print(f\"Balanced traffic condition: green time = {default_green_time}\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        \n",
    "    elif vehicles_road1 > vehicles_road2:\n",
    "        # More traffic on road 1, extend green time\n",
    "        additional_time = min(60, (vehicles_road1 - vehicles_road2) * 2)\n",
    "        green_time_road1 += additional_time\n",
    "        print(f\"Road 1 has more traffic. Green time = {green_time_road1}\")\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(green_time_road1)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "    else:\n",
    "        # More traffic on road 2, extend green time\n",
    "        additional_time = min(60, (vehicles_road2 - vehicles_road1) * 2)\n",
    "        green_time_road2 += additional_time\n",
    "        print(f\"Road 2 has more traffic. Green time = {green_time_road2}\")\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"green\")\n",
    "        time.sleep(green_time_road2)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light2_red, light2_orange, light2_green, \"red\")\n",
    "        set_light(light1_red, light1_orange, light1_green, \"green\")\n",
    "        time.sleep(default_green_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"orange\")\n",
    "        time.sleep(orange_time)\n",
    "        \n",
    "        set_light(light1_red, light1_orange, light1_green, \"red\")\n",
    "    \n",
    "    return green_time_road1, green_time_road2, orange_time_road1, orange_time_road2\n",
    "\n",
    "\n",
    "# Define the paths to the images for both roads\n",
    "images_road1 = [f\"pic1\\\\image ({i}).jpg\" for i in range(1, 9)]\n",
    "images_road2 = [f\"pic1\\\\image ({i}).jpg\" for i in range(9, 17)]\n",
    "\n",
    "# images_road1 = [f\"pic2\\\\image{i}.jpeg\" for i in range(1, 9)]\n",
    "# images_road2 = [f\"pic2\\\\image{i}.jpeg\" for i in range(9, 17)]\n",
    "\n",
    "# Step 1: Print all class indices detected by YOLO for an image\n",
    "sample_results = model(images_road1[0])  # Run on a sample image\n",
    "for box in sample_results[0].boxes.data:\n",
    "    print(f\"Class index detected: {int(box[-1])}\")\n",
    "\n",
    "# Update vehicle_classes based on the printed indices for your model\n",
    "vehicle_classes = [2, 3, 5, 7]  # Example class indices (e.g., 2: car, 3: truck, etc.)\n",
    "\n",
    "# Step 2: Count all detected vehicle types based on the identified indices\n",
    "for image_path_road1, image_path_road2 in zip(images_road1, images_road2):\n",
    "    # Run YOLO prediction for both images\n",
    "    results_road1 = model(image_path_road1)\n",
    "    results_road2 = model(image_path_road2)\n",
    "  \n",
    "    # Count all detected vehicle classes in each road's image\n",
    "    vehicles_road1 = sum(1 for box in results_road1[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "    vehicles_road2 = sum(1 for box in results_road2[0].boxes.data if int(box[-1]) in vehicle_classes)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update traffic lights based on YOLO results and capture returned values\n",
    "    green_time_road1, green_time_road2, orange_time_road1, orange_time_road2 = update_lights(vehicles_road1, vehicles_road2)\n",
    "\n",
    "    image_with_boxes1 = draw_bounding_boxes(image_path_road1, results_road1)\n",
    "    image_with_boxes2 = draw_bounding_boxes(image_path_road2, results_road2)\n",
    "    \n",
    "    # Print the green and orange times for both roads\n",
    "    print(f\"Road 1 green time: {green_time_road1}, Orange time: {orange_time_road1}\")\n",
    "    print(f\"Road 2 green time: {green_time_road2}, Orange time: {orange_time_road2}\")\n",
    "    print(f\"Total vehicles on road 1: {vehicles_road1}\")\n",
    "    print(f\"Total vehicles on road 2: {vehicles_road2}\")\n",
    "\n",
    "    # Display images after prediction\n",
    "    img1 = ImageTk.PhotoImage(image_with_boxes1.resize((400, 350)))\n",
    "    img2 = ImageTk.PhotoImage(image_with_boxes2.resize((400, 350)))\n",
    "    \n",
    "    # Clear previous images\n",
    "    for widget in frame_images.winfo_children():\n",
    "        widget.destroy()\n",
    "        \n",
    "    # Display the current images\n",
    "    label_road1 = tk.Label(frame_images, image=img1)\n",
    "    label_road1.image = img1  # Keep a reference to avoid garbage collection\n",
    "    label_road1.pack(side=tk.LEFT)\n",
    "\n",
    "    label_road2 = tk.Label(frame_images, image=img2)\n",
    "    label_road2.image = img2  # Keep a reference to avoid garbage collection\n",
    "    label_road2.pack(side=tk.LEFT)\n",
    "\n",
    "    # Log or save results as needed for each image\n",
    "    print(f\"Processed {image_path_road1} and {image_path_road2}\")\n",
    "\n",
    "    # Add a delay to simulate a real camera feed\n",
    "    time.sleep(1)  # Delay of 1 second\n",
    "\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746b2a6-e6b3-40b4-8215-d22338bc8064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
